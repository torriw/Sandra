---
title: "Untitled"
output: html_document
date: "2023-05-23"
---

```{r }
home<-setwd("C:/Users/torriw/Desktop/sandra")
```

```{r }
final_neuro<-read.csv("C:/Users/torriw/Desktop/sandra/final_neuro.csv")
final_neuro<-final_neuro[,-1]
neuro_range<-sapply(final_neuro, function(final_neuro) max(final_neuro, na.rm=TRUE) - min(final_neuro, na.rm=TRUE))
range_list<-data.frame(neuro_range)
write.csv(range_list,"C:/Users/torriw/Desktop/sandra/neuro_range_list.csv",row.names = F)
```


```{r }
library(dplyr)
norm_group<-read.csv("C:/Users/torriw/Desktop/sandra/norm_group.csv")
norm_group_1<-norm_group[,-1]
#inverse normalization transformation function
inormal <- function(x) 
{   qnorm((rank(x, na.last = "keep") - 0.5) / sum(!is.na(x))) }


invnormgroup <- mutate(norm_group_1, across(everything(), inormal))
invnormgroup<-cbind(norm_group$IID,invnormgroup)
write.csv(invnormgroup,"C:/Users/torriw/Desktop/sandra/invnormgroup.csv",row.names = F)
```

```{r }
data_dir <- paste0( home, "/alox15_glm/" )
out_data <- paste0 (home, "/Output/" )

filenames <- list.files(path = data_dir, pattern = "*.linear", full.names = FALSE)

out_name <- "Summary File.csv"

```

```{r }
library(dplyr)
df_header <- data.frame()
df_header[1,1] <- "Welcome!"
df_header[1,2] <- "Processing Gene SLC44A1"
df_header[1,3] <- "SNPs Present: 78"  # This is not correct. It must be altered in the plink.pgen file using the SNP validation from ENSEMBLE
df_header[1,4] <- "Covariates: 1"
df_header[1,5] <- paste0( "Endpoints: ", length(filenames) )
df_header[1,6] <- ""  # Empty column for header reasons
# df_header[1,7] <- ""  # Empty column for header reasons

df_header[2,] <- c("")  # empty line
# Following line must have as many elements as columns
df_header[3,] <- c( "Neurobehavioural Measurment", "All SNPs", "Type of model", "Significant ADD", "0.1 Sig ADD", "number of SNPs with Association" )

names(df_header) <- df_header[1,]; df_header <- df_header[-1,]  # Assign column names as first row then remove first row
#### ####

# For every variant in every file perform these tests
# 1. is the ADD model sig [if T then Keep]
# 2. is the ADDxFAS model sig [if T then Keep]
# 3. in those variants are there additional covariats [note additional covariate interaction effects]
# 4. perform a bonferroni correction at n=104
# p.adjust(0.0004807, method = "bonferroni", n = 104)  ## 0.05
# p.adjust(0.001, method = "bonferroni", n = 104)      ## 0.104
# This can be q-value of 0.0005  
##################################################
write_df <- data.frame()
for( i in filenames ){
  # print( paste0( "Beginning search for ", i))
  
  # Step 1: Read the file
  x <- read.csv( paste0( data_dir, i ), sep = "\t")
  
  
  df <- NULL
  variant_name <- NULL
  variant_covar <- NULL
  #variant_sig <- NULL
  variant_ADDxsig <- NULL
  variant_ADDxsig0.1 <- NULL
  for( j in unique(x$ID) ){
    df_variant <- x[x$ID==j,]
    
    # test if none of the p-values are significant; then skip to next variant
    if( !any(which(df_variant$P < 0.05)) ){
      next
    }
    # test if the additive and interaction with FAS is sig; if NOT then skip
    
    sig_add <- 
      df_variant$P[ df_variant$TEST == "ADD" ] < 0.05
    sig_fas <- 
      df_variant$P[ df_variant$TEST =="ADDxFASStatus=FAS"] < 0.05
    # This is a NAND; will only pass if both sig_add and sig_fas are TRUE
    
    if( !isTRUE(sig_fas) ) {next}  # This is a check for Logical(0)
    if( !sig_fas ){
      next
    }
    
    
    # c3 <- "ADD | ADDxFASStatus=FAS"
    other_covar <-
      df_variant$TEST[ df_variant$P < 0.05 ]
    
    # This is a missleading significance
    #sig <- any(p.adjust( df_variant$P, method = "bonferroni", n = 78 ) < 0.05)
    ADDxsig <- any(
      p.adjust( df_variant$P[ df_variant$TEST =="ADDxFASStatus" ],
                method = "bonferroni", n = 78 ) < 0.05 )
    
    ADDxsig0.1 <- any(
      p.adjust( df_variant$P[ df_variant$TEST == "ADDxFASStatus" ],
                method = "bonferroni", n = 78 ) < 0.1 )
    
    variant_name <- c(variant_name, df_variant$ID[1])
    variant_covar <- c(variant_covar, paste0( other_covar, collapse = ", "), 
                       collapse = " | ")
    #variant_sig <- c(variant_sig, paste0( sig ))
    variant_ADDxsig <- c( variant_ADDxsig, paste0( ADDxsig ))
    variant_ADDxsig0.1 <- c( variant_ADDxsig0.1, paste0( ADDxsig0.1 ))  
    
    # print(variant_name)
  }
    
    
  # Write the data that you want to keep
  # Is the additive or the interaction present?
  # In which genes was this present
  # is there a bonferroni correction significance?
  
  ## IMPORTANT: MAKE A NEW ROW !! (using `nrow()+1`) ## Then adding data will be in sync with that row using `nrow()`
  write_df[ nrow(write_df) + 1, 1 ] <- stringr::str_remove(i, "plink2.") %>% stringr::str_remove(., ".glm.linear")  # the neurobehaviour measurement NAME
  
  write_df[ nrow(write_df), 2 ] <- paste( variant_name, collapse = ", " )  # all of the variants separated by ", "
  
  write_df[ nrow(write_df), 3 ] <- paste( variant_covar, collapse = "" )  # Other Covariates
  
  # is there a bonferroni correction significance?
  # The p-value correction should be performed based on the number of variants tested
  # at present this is 120 soon to be 104
  # The presence of a p-value is recorded for each variable times the number of covariates. This is why I am performing a manual p-adjustment at Bonferroni n = 104.
  ##### DEPRECIATED
  # manual_qvalue <- sapply( df$P, function(x){
  #   return( p.adjust(x, method = "bonferroni", n = 104) ) 
  # })
  # write_df[ nrow(write_df), 4 ] <- any( manual_qvalue <= 0.05 )  
  #####
  #write_df[ nrow(write_df), 4 ] <- paste( variant_sig, collapse = " | " )  # Necessary for sig_write_df
  write_df[ nrow(write_df), 4 ] <- paste( variant_ADDxsig, collapse = " | ")
  write_df[ nrow(write_df), 5 ] <- paste( variant_ADDxsig0.1, collapse = " | ")
  write_df[ nrow(write_df), 6 ] <- length(unique(variant_name)) 
  
}


##################################################


sig_write_df <- write_df
names(sig_write_df) <- names(df_header)
df_out <- rbind(df_header, sig_write_df)

write.csv( x = df_out, 
           file = paste0( out_data, out_name ),
           row.names = FALSE)

### THIS... I don't even know
# Only write the sig rows
## This line will only work if the 4th column is a TRUTH boolean column
sig_write_df <- sig_write_df[ c( 
                                grep(write_df[,4], pattern = "TRUE")
                                ), ]
sig_df_out <- rbind(df_header, sig_write_df)

write.csv( x = sig_df_out,
           file = paste0( out_data, "sig_", out_name ),
           row.names = FALSE)
##################################################
```

```{r }
# data sets are too large to parse, have to cut down size by setting parameters
filtered_data<-data.frame()
for (i in filenames){
  x <- read.csv( paste0( data_dir, i ), sep = "\t")
  #add row of repeating dysm names so when the files are rbinded, I can distinguish their values & dysm names 
  x$NBs<-rep(stringr::str_remove(i, "plink2.") %>% stringr::str_remove(., ".glm.linear"),nrow(x)) 
  x<-x[x$TEST == "ADDxFASStatus=FAS" & x$P < 0.0009,] #this line is for chr pairs w p's at cutoff value
  filtered_data<-rbind(filtered_data,x)
}

#write out the filtered data in separate file 
write.csv(filtered_data,"C:/Users/torriw/Desktop/sandra/filtered_data/alox15_filtered.csv",row.names = F )


```

```{r }



```

